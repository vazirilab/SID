
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>LS_nnls</title><meta name="generator" content="MATLAB 9.3"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2018-05-29"><meta name="DC.source" content="LS_nnls.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#2">LS_NNLS  Solver for large non-negative least-squares problems</a></li><li><a href="#3">Set default values for parameters not set by user</a></li><li><a href="#4">Compute the first term of the gradient that won&#8217;t change throughout the function</a></li><li><a href="#5">Assert that the dimensions of the input corresponds to an NNLS problem</a></li><li><a href="#6">Compute the second term (the Gramian matrix) that does not change throughout the function</a></li><li><a href="#7">Loop until all sub-problems have been solved to within desired accuracy</a></li><li><a href="#9">Projected gradient descent with exact line search update</a></li><li><a href="#10">If max. iterations has not been reached, log consecutive error history (see function help)</a></li><li><a href="#11">If one of the nnls-sub-problems k is finished (id(k)==true), transfer k from the GPU to the output array</a></li></ul></div><pre class="codeinput"><span class="keyword">function</span> [X, G] = LS_nnls(A, Y, opts, G, x)
</pre><h2 id="2">LS_NNLS  Solver for large non-negative least-squares problems</h2><p>Solves argmin_{x&gt;=0}||y-A(x)||_2^2</p><p>Input: A              Matrix corresponding to A in the formula above. x              Matrix of solution vectros of the above problem. LS_nnls                   solves multiple nnls problems in parallel. Y              Matrix of inhomogenities, each row represents one nnls                   problm. struct opts opts.display   boolean, if true messages will be printed in console. opts.lambda    lagrangian multiplier for L1 regularization opts.gpu_id    ID of GPU to be used if GPU support is available. opts.use_std   calculate least standard deviation instead of L2-norm opts.sample    Read about convergence check below! opts.tol       - opts.tol_      -</p><p>Output X              Matrix of approximations of the solutions to the                   nnls problems. Each row is one solution. G              Gramian matrix.</p><p>Convergence check: LS_nnls checks for each of the nnls subproblem if a certain accuracy is reached. It does that no like usually by checking the norm of the gradient, but by guessing the convergence curve from the difference between two consecutive iterative solutions (Consec_error). It performs a linear fit of the log of Consec_error for opts.sample previous iterates and if the error between the linear fit and the log of the consecutive error is smaller than opts.tol_ the algorithm can use this information to accurately estimate the true error. If the true error is below opts.tol the algorithm stops for the nnls-sub-problem in question and puts the current solution into the output array.</p><h2 id="3">Set default values for parameters not set by user</h2><pre class="codeinput"><span class="keyword">if</span> nargin&lt;3
    opts =struct;
<span class="keyword">end</span>

<span class="keyword">if</span> ~isfield(opts,<span class="string">'display'</span>)
    opts.display = false;
<span class="keyword">end</span>

<span class="keyword">if</span> ~isfield(opts,<span class="string">'use_std'</span>)
    opts.use_std = false;
<span class="keyword">end</span>

<span class="keyword">if</span> ~isfield(opts,<span class="string">'lambda'</span>)
    opts.lambda = 0;
<span class="keyword">end</span>

<span class="keyword">if</span> ~isfield(opts,<span class="string">'gpu_id'</span>)
    opts.gpu_id = [];
<span class="keyword">end</span>

<span class="keyword">if</span> ~isfield(opts,<span class="string">'sample'</span>)
    opts.sample = 300;
<span class="keyword">end</span>

<span class="keyword">if</span> ~isfield(opts,<span class="string">'tol'</span>)
    opts.tol = 1e-7;
<span class="keyword">end</span>

<span class="keyword">if</span> ~isfield(opts,<span class="string">'tol_'</span>)
    opts.tol_ = 1e-2;
<span class="keyword">end</span>

<span class="keyword">if</span> ~isfield(opts,<span class="string">'max_iter'</span>)
    opts.max_iter = 2000;
<span class="keyword">end</span>
</pre><h2 id="4">Compute the first term of the gradient that won&#8217;t change throughout the function</h2><pre class="codeinput">h = A'*Y - opts.lambda;
</pre><h2 id="5">Assert that the dimensions of the input corresponds to an NNLS problem</h2><pre class="codeinput"><span class="keyword">if</span> nargin&lt;5
    x = zeros(size(A,2),size(Y,2));
    <span class="keyword">if</span> nargin&lt;4
        G = A'*A;
    <span class="keyword">elseif</span> size(G,1)~=size(A,2)
        disp(<span class="string">'G has wrong dimensions.'</span>)
        <span class="keyword">return</span>
    <span class="keyword">end</span>
<span class="keyword">elseif</span> (size(x,1)~=size(A,2))||(size(x,2)~=size(Y,2))
    disp(<span class="string">'x has wrong dimensions.'</span>)
    <span class="keyword">return</span>
<span class="keyword">end</span>
X = x;
<span class="keyword">if</span> ~isempty(opts.gpu_id)
    gpuDevice(opts.gpu_id);
    x = gpuArray(x);
    h = gpuArray(h);
    G= gpuArray(G);
<span class="keyword">end</span>
rds=1:size(Y,2);
</pre><h2 id="6">Compute the second term (the Gramian matrix) that does not change throughout the function</h2><pre class="codeinput"><span class="keyword">if</span> opts.use_std
    G = @(x) G*x - (G*sum(x,2))/size(Y,2);
    h = h - A'*sum(Y,2)/size(Y,2);
<span class="keyword">else</span>
    G = @(x) G*x;
<span class="keyword">end</span>
</pre><h2 id="7">Loop until all sub-problems have been solved to within desired accuracy</h2><pre class="codeinput">iter = 0;
test=[];
dn=[[1:2:2*opts.sample]', ones(opts.sample,1)];
Xi=inv(dn'*dn)*dn';
tic
<span class="keyword">while</span> ~isempty(x)
</pre><pre class="codeinput">    iter = iter + 1;
</pre><h2 id="9">Projected gradient descent with exact line search update</h2><pre class="codeinput">    x_ = gather(x);
    df = -h + G(x);
    passive=max(x&gt;0,df&lt;0);
    df_=df.*passive;
    alpha=sum(df_.^2,1)./sum(df_.*(G(df_)),1);
    alpha(isnan(alpha))=0;
    x = x - df_.*alpha;
    x(x&lt;0) = 0;
</pre><h2 id="10">If max. iterations has not been reached, log consecutive error history (see function help)</h2><p>wait for two times opts.sample and then use the error estimator</p><pre class="codeinput">    <span class="keyword">if</span> iter&gt;opts.max_iter
        ids=true(1,size(x,2));
        <span class="keyword">if</span> opts.display
            disp(<span class="string">'Max. number of iterations has been reached.'</span>);
        <span class="keyword">end</span>
    <span class="keyword">elseif</span> ~opts.use_std
        <span class="keyword">if</span> mod(iter,2)==1
            test = [test' log((sum(gather(x)-x_,1).^2)./sum(x_.^2,1))'/2]';
            <span class="keyword">if</span> size(test,1)&gt;opts.sample
                test=test(2:end,:);
            <span class="keyword">end</span>
            <span class="keyword">if</span> iter&gt;2*opts.sample
                k = Xi*test;
                ids = logical(max(((exp(test(end,:))./(1 - exp(k(1))))&lt;opts.tol).*<span class="keyword">...</span>
                    (sum(abs(dn*k-test),1)&lt;opts.tol_*opts.sample).*<span class="keyword">...</span>
                    (exp(k(1,:))&lt;1),test(end,:)==-inf));
                <span class="comment">%                 ids = logical(max((max(passive)==0),(exp(test(end,:))./(1-exp(k(1,:)))&lt;opts.tol*size(x,1)*max(x,[],1)).*(sum(abs(dn*k-test),1)&lt;opts.tol_*opts.sample).*(exp(k(1,:))&lt;1)));</span>
            <span class="keyword">else</span>
                ids = false(1,size(x,2));
            <span class="keyword">end</span>
        <span class="keyword">else</span>
            ids=[];
        <span class="keyword">end</span>
    <span class="keyword">else</span>
        ids = [];
    <span class="keyword">end</span>
</pre><h2 id="11">If one of the nnls-sub-problems k is finished (id(k)==true), transfer k from the GPU to the output array</h2><pre>and delete it from the current job description</pre><pre class="codeinput">    <span class="keyword">if</span> max(ids(:))
        <span class="keyword">if</span> ~isempty(opts.gpu_id)
            X(:,rds(ids)) = gather(x(:,ids));
        <span class="keyword">else</span>
            X(:,rds(ids)) = x(:,ids);
        <span class="keyword">end</span>
        rds = rds(~ids);
        x=x(:,~ids);
        h=h(:,~ids);
        test = test(:,~ids);
    <span class="keyword">end</span>
    <span class="keyword">if</span> opts.display
        disp(iter);
    <span class="keyword">end</span>
</pre><pre class="codeinput"><span class="keyword">end</span>

<span class="keyword">if</span> opts.display
    toc
<span class="keyword">end</span>
</pre><pre class="codeinput"><span class="keyword">end</span>
</pre><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2017b</a><br></p></div><!--
##### SOURCE BEGIN #####
function [X, G] = LS_nnls(A, Y, opts, G, x)
%% LS_NNLS  Solver for large non-negative least-squares problems
%
% Solves argmin_{x>=0}||y-A(x)||_2^2
%
% Input:
% A              Matrix corresponding to A in the formula above.
% x              Matrix of solution vectros of the above problem. LS_nnls
%                   solves multiple nnls problems in parallel.
% Y              Matrix of inhomogenities, each row represents one nnls
%                   problm.
% struct opts
% opts.display   boolean, if true messages will be printed in console.
% opts.lambda    lagrangian multiplier for L1 regularization
% opts.gpu_id    ID of GPU to be used if GPU support is available.
% opts.use_std   calculate least standard deviation instead of L2-norm
% opts.sample    Read about convergence check below!
% opts.tol       -
% opts.tol_      -
%
% Output
% X              Matrix of approximations of the solutions to the
%                   nnls problems. Each row is one solution.
% G              Gramian matrix.
%
% Convergence check:
% LS_nnls checks for each of the nnls subproblem if a certain accuracy is
% reached. It does that no like usually by checking the norm of the
% gradient, but by guessing the convergence curve from the difference
% between two consecutive iterative solutions (Consec_error).
% It performs a linear fit of the log of Consec_error for opts.sample
% previous iterates and if the error between the linear fit and the log of
% the consecutive error is smaller than opts.tol_ the algorithm can use
% this information to accurately estimate the true error. If the true error
% is below opts.tol the algorithm stops for the nnls-sub-problem in
% question and puts the current solution into the output array.

%% Set default values for parameters not set by user
if nargin<3
    opts =struct;
end

if ~isfield(opts,'display')
    opts.display = false;
end

if ~isfield(opts,'use_std')
    opts.use_std = false;
end

if ~isfield(opts,'lambda')
    opts.lambda = 0;
end

if ~isfield(opts,'gpu_id')
    opts.gpu_id = [];
end

if ~isfield(opts,'sample')
    opts.sample = 300;
end

if ~isfield(opts,'tol')
    opts.tol = 1e-7;
end

if ~isfield(opts,'tol_')
    opts.tol_ = 1e-2;
end

if ~isfield(opts,'max_iter')
    opts.max_iter = 2000;
end

%% Compute the first term of the gradient that wonâ€™t change throughout the function
h = A'*Y - opts.lambda;

%% Assert that the dimensions of the input corresponds to an NNLS problem
if nargin<5
    x = zeros(size(A,2),size(Y,2));
    if nargin<4
        G = A'*A;
    elseif size(G,1)~=size(A,2)
        disp('G has wrong dimensions.')
        return
    end
elseif (size(x,1)~=size(A,2))||(size(x,2)~=size(Y,2))
    disp('x has wrong dimensions.')
    return
end
X = x;
if ~isempty(opts.gpu_id)
    gpuDevice(opts.gpu_id);
    x = gpuArray(x);
    h = gpuArray(h);
    G= gpuArray(G);
end
rds=1:size(Y,2);

%% Compute the second term (the Gramian matrix) that does not change throughout the function
if opts.use_std
    G = @(x) G*x - (G*sum(x,2))/size(Y,2);
    h = h - A'*sum(Y,2)/size(Y,2);
else
    G = @(x) G*x;
end

%% Loop until all sub-problems have been solved to within desired accuracy
iter = 0;
test=[];
dn=[[1:2:2*opts.sample]', ones(opts.sample,1)];
Xi=inv(dn'*dn)*dn';
tic
while ~isempty(x)
    iter = iter + 1;

    %% Projected gradient descent with exact line search update
    x_ = gather(x);
    df = -h + G(x);
    passive=max(x>0,df<0);
    df_=df.*passive;
    alpha=sum(df_.^2,1)./sum(df_.*(G(df_)),1);
    alpha(isnan(alpha))=0;
    x = x - df_.*alpha;
    x(x<0) = 0;
    
    %% If max. iterations has not been reached, log consecutive error history (see function help)
    % wait for two times opts.sample and then use the error estimator
    if iter>opts.max_iter
        ids=true(1,size(x,2));
        if opts.display
            disp('Max. number of iterations has been reached.');
        end
    elseif ~opts.use_std
        if mod(iter,2)==1
            test = [test' log((sum(gather(x)-x_,1).^2)./sum(x_.^2,1))'/2]';
            if size(test,1)>opts.sample
                test=test(2:end,:);
            end
            if iter>2*opts.sample
                k = Xi*test;
                ids = logical(max(((exp(test(end,:))./(1 - exp(k(1))))<opts.tol).*...
                    (sum(abs(dn*k-test),1)<opts.tol_*opts.sample).*...
                    (exp(k(1,:))<1),test(end,:)==-inf));
                %                 ids = logical(max((max(passive)==0),(exp(test(end,:))./(1-exp(k(1,:)))<opts.tol*size(x,1)*max(x,[],1)).*(sum(abs(dn*k-test),1)<opts.tol_*opts.sample).*(exp(k(1,:))<1)));
            else
                ids = false(1,size(x,2));
            end
        else
            ids=[];
        end
    else
        ids = [];
    end
    
    %% If one of the nnls-sub-problems k is finished (id(k)==true), transfer k from the GPU to the output array
    %  and delete it from the current job description
    if max(ids(:))
        if ~isempty(opts.gpu_id)
            X(:,rds(ids)) = gather(x(:,ids));
        else
            X(:,rds(ids)) = x(:,ids);
        end
        rds = rds(~ids);
        x=x(:,~ids);
        h=h(:,~ids);
        test = test(:,~ids);
    end
    if opts.display
        disp(iter);
    end
end

if opts.display
    toc
end

end

##### SOURCE END #####
--></body></html>